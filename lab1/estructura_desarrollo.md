## Estructura Actual del Proyecto

### Datos
- **lab1_materials/**: Datasets originales (train/test)
- **preprocessed_data/**: Datos preprocesados (2 versiones)
- **results/**: Predicciones y comparaciones de modelos

### Notebooks
1. **01_data_exploration.ipynb** - An치lisis exploratorio inicial
2. **02_preprocessing.ipynb** - Limpieza y preprocesamiento
3. **03_model_comparison.ipynb** - Comparaci칩n de modelos cl치sicos
4. **03-09_*.ipynb** - Fine-tuning de LLMs:
   - f2llm-4B (tweet + text_clean)
   - KaLM (tweet + text_clean)
   - Ministral3-8B (inference + fine-tuning)

### Resultados
- Predicciones JSON por modelo
- Comparaciones CSV
- Modelos cl치sicos en `results/clasicos/`

---

## Experimentos Pendientes

### 游댠 Prioridad Alta (R치pido + Impacto)
- [ ] **BETO fine-tuned**: Transformer espa침ol ligero y efectivo
- [ ] **Ensemble**: Votaci칩n/stacking de mejores modelos actuales
- [ ] **An치lisis de errores**: Matriz confusi칩n + tweets mal clasificados
- [ ] **Threshold tuning**: Optimizar umbral de decisi칩n por modelo

### 游늵 An치lisis y Mejoras
- [ ] **Sample weights**: Usar task1_agreement del gold
- [ ] **Validaci칩n cruzada**: Para LLMs (actualmente solo train/test)
- [ ] **Calibraci칩n**: Temperatura del softmax

### 游빍 Modelos Adicionales
- [ ] **RoBERTa-es / mBERT / XLM-RoBERTa**
- [ ] **Data Augmentation**: Back-translation, parafraseo
- [ ] **Prompt Engineering**: Diferentes prompts para LLMs
- [ ] **Few-shot learning**: Ejemplos en el prompt