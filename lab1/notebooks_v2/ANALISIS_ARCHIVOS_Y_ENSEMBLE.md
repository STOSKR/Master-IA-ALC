# An√°lisis de Archivos JSON y Ensemble Conservador

## üìÅ ¬øPor qu√© hay tantos archivos JSON?

Cada modelo genera varios archivos con prop√≥sitos espec√≠ficos:

### **Archivos Est√°ndar (la mayor√≠a de modelos):**
```
üìÇ results_v2/[MODELO]/predictions/
  ‚îú‚îÄ‚îÄ dev_predictions_temp.json      ‚Üê Predicciones en validaci√≥n
  ‚îú‚îÄ‚îÄ dev_gold_temp.json             ‚Üê Ground truth de validaci√≥n
  ‚îî‚îÄ‚îÄ BeingChillingWeWillWin_*.json  ‚Üê Predicciones de TEST (para competici√≥n)
```

### **F2LLM-4B (caso especial - DOBLE):**
```
üìÇ results_v2/F2LLM-4B/predictions/
  ‚îú‚îÄ‚îÄ dev_predictions_temp.json            ‚Üê Validaci√≥n con "tweet" (texto original)
  ‚îú‚îÄ‚îÄ dev_predictions_temp_clean.json      ‚Üê Validaci√≥n con "text_clean" (limpio)
  ‚îú‚îÄ‚îÄ dev_gold_temp.json                   ‚Üê Ground truth para "tweet"
  ‚îú‚îÄ‚îÄ dev_gold_temp_clean.json             ‚Üê Ground truth para "text_clean"
  ‚îú‚îÄ‚îÄ BeingChillingWeWillWin_f2llm4B.json       ‚Üê TEST con "tweet"
  ‚îî‚îÄ‚îÄ BeingChillingWeWillWin_f2llm4Bclean.json  ‚Üê TEST con "text_clean"
```
**Raz√≥n:** Se entrenaron DOS versiones con diferentes columnas de texto.

### **KaLM (caso problem√°tico):**
```
üìÇ results_v2/KaLM/predictions/
  ‚îú‚îÄ‚îÄ dev_predictions_temp.json      ‚Üê COMPARTIDO por ambas versiones ‚ö†Ô∏è
  ‚îú‚îÄ‚îÄ dev_gold_temp.json             ‚Üê Ground truth compartido
  ‚îú‚îÄ‚îÄ BeingChillingWeWillWin_KaLM.json       ‚Üê TEST con "tweet"
  ‚îî‚îÄ‚îÄ BeingChillingWeWillWin_KaLMclean.json  ‚Üê TEST con "text_clean"
```
**Problema detectado:** Ambos KaLM (Tweet y Text Clean) usan el MISMO archivo de validaci√≥n, 
lo que significa que en validaci√≥n generan predicciones id√©nticas. Solo difieren en TEST.

---

## üö´ Modelos EXCLUIDOS y por qu√©

### **3Ministral8B_LoRA (con fine-tuning) - DESASTRE TOTAL**
```
M√©tricas de validaci√≥n:
  Accuracy:  0.5725  ‚ùå
  Precision: 0.9000  
  Recall:    0.0444  ‚ùå‚ùå‚ùå (pr√°cticamente no detecta la clase YES)
  F1-Score:  0.0847  ‚ùå‚ùå‚ùå (PEOR QUE TIRAR UNA MONEDA)
```
**Veredicto:** El fine-tuning EMPEOR√ì el modelo base. No aporta nada al ensemble.

### **KaLM Text Clean - Redundante**
```
F1 Score: 0.8000
```
**Raz√≥n:** Comparte archivo de validaci√≥n con KaLM Tweet (F1: 0.8254), por lo que sus 
predicciones son id√©nticas en validaci√≥n. Incluir ambos inflar√≠a artificialmente el ensemble.

---

## ‚úÖ TOP 5 CONSERVADOR (Ensemble Final)

| # | Modelo | F1 Score | Tipo | Comentario |
|---|--------|----------|------|-----------|
| 1 | **F2LLM-4B Tweet** | 0.8532 | LLM | ü•á Mejor modelo individual |
| 2 | **F2LLM-4B Text Clean** | 0.8317 | LLM | ü•à Segunda mejor variante |
| 3 | **KaLM Tweet** | 0.8254 | LLM | ü•â Tercer mejor LLM |
| 4 | **Ministral 3B** | 0.8073 | LLM | Sin fine-tuning, s√≥lido |
| 5 | **LogisticRegression (TF-IDF)** | 0.7251 | ML Cl√°sico | Diversidad de enfoque |

### **Ventajas de este ensemble:**
- ‚úÖ Solo modelos con validaci√≥n independiente
- ‚úÖ Todos tienen F1 > 0.70
- ‚úÖ Diversidad: 4 LLMs + 1 modelo cl√°sico
- ‚úÖ Ning√∫n modelo redundante o problem√°tico

---

## üìä Comparaci√≥n de Archivos por Modelo

| Modelo | Val Preds | Val Gold | Test Preds | F1 Score |
|--------|-----------|----------|------------|----------|
| F2LLM-4B Tweet | `dev_predictions_temp.json` | `dev_gold_temp.json` | `BeingChillingWeWillWin_f2llm4B.json` | 0.8532 |
| F2LLM-4B Clean | `dev_predictions_temp_clean.json` | `dev_gold_temp_clean.json` | `BeingChillingWeWillWin_f2llm4Bclean.json` | 0.8317 |
| KaLM Tweet | `dev_predictions_temp.json` | `dev_gold_temp.json` | `BeingChillingWeWillWin_KaLM.json` | 0.8254 |
| ~~KaLM Clean~~ | ~~`dev_predictions_temp.json` (compartido)~~ | ~~`dev_gold_temp.json`~~ | ~~`BeingChillingWeWillWin_KaLMclean.json`~~ | ~~0.8000~~ |
| Ministral3B | `dev_predictions_temp.json` | `dev_gold_temp.json` | `BeingChillingWeWillWin_Mistral3B.json` | 0.8073 |
| ~~3Ministral8B_LoRA~~ | ~~`dev_predictions_temp.json`~~ | ~~`dev_gold_temp.json`~~ | ~~`BeingChillingWeWillWin_3Ministral8B_ft.json`~~ | ~~0.0847~~ |
| LogReg TF-IDF | `val_predictions_temp.json` | `val_gold_temp.json` | `BeingChillingWeWillWin_LogisticRegression_TFIDF.json` | 0.7251 |

---

## üìù Archivos Generados por el Ensemble

```
üìÇ results_v2/ensemble/
  ‚îú‚îÄ‚îÄ BeingChillingWeWillWin_ensemble_top5_conservador.json     ‚Üê TEST (para competici√≥n)
  ‚îî‚îÄ‚îÄ BeingChillingWeWillWin_ensemble_top5_conservador_val.json ‚Üê Validaci√≥n (para evaluaci√≥n)
```

---

## üéØ Recomendaci√≥n Final

**Para la competici√≥n, considera estos dos archivos:**

1. **Si quieres el modelo M√ÅS SEGURO:**
   ```
   results_v2/F2LLM-4B/predictions/BeingChillingWeWillWin_f2llm4B.json
   ```
   - F1: **0.8532** (probado en validaci√≥n)
   - Modelo individual m√°s robusto

2. **Si quieres probar el ENSEMBLE:**
   ```
   results_v2/ensemble/BeingChillingWeWillWin_ensemble_top5_conservador.json
   ```
   - Combina los 5 mejores modelos por votaci√≥n mayoritaria
   - Podr√≠a mejorar 1-2% sobre el mejor individual
   - Reduce riesgo de errores individuales

**Mi recomendaci√≥n personal:** Eval√∫a primero el ensemble en validaci√≥n. Si mejora F1 en ‚â•0.01 
sobre F2LLM-4B Tweet, usa el ensemble. Si no, qu√©date con F2LLM-4B Tweet.

---

## üîß Limpieza de results_v2

El script `clean_results_v2.py` eliminar√°:
- ‚ùå Checkpoints (archivos `.pth`, `.bin`, `.safetensors`)
- ‚ùå Pesos del modelo (`lora_weights/`, `model/`)
- ‚ùå Configuraciones intermedias
- ‚úÖ **Mantiene:** Solo los archivos JSON de predicciones

**Ahorro de espacio estimado:** 10-50 GB (dependiendo de los checkpoints)
