{
  "best_global_step": 1290,
  "best_metric": 0.8018757327080891,
  "best_model_checkpoint": "../results_v2/KaLM/text_clean/checkpoint-1290",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3225,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07751937984496124,
      "grad_norm": 2.1098008155822754,
      "learning_rate": 4.997152524340171e-05,
      "loss": 0.7013,
      "step": 50
    },
    {
      "epoch": 0.15503875968992248,
      "grad_norm": 5.945865631103516,
      "learning_rate": 4.9883832649612775e-05,
      "loss": 0.695,
      "step": 100
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 4.512145519256592,
      "learning_rate": 4.973711835398576e-05,
      "loss": 0.6911,
      "step": 150
    },
    {
      "epoch": 0.31007751937984496,
      "grad_norm": 1.7511240243911743,
      "learning_rate": 4.953173034662064e-05,
      "loss": 0.6806,
      "step": 200
    },
    {
      "epoch": 0.3875968992248062,
      "grad_norm": 3.468454599380493,
      "learning_rate": 4.9268155785179295e-05,
      "loss": 0.6625,
      "step": 250
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 2.0989580154418945,
      "learning_rate": 4.89470198394013e-05,
      "loss": 0.6493,
      "step": 300
    },
    {
      "epoch": 0.5426356589147286,
      "grad_norm": 3.820000171661377,
      "learning_rate": 4.856908420827041e-05,
      "loss": 0.6062,
      "step": 350
    },
    {
      "epoch": 0.6201550387596899,
      "grad_norm": 4.599498748779297,
      "learning_rate": 4.813524531334873e-05,
      "loss": 0.5385,
      "step": 400
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 13.014411926269531,
      "learning_rate": 4.7646532172563765e-05,
      "loss": 0.531,
      "step": 450
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 16.36224365234375,
      "learning_rate": 4.710410395949164e-05,
      "loss": 0.5012,
      "step": 500
    },
    {
      "epoch": 0.8527131782945736,
      "grad_norm": 2.3052384853363037,
      "learning_rate": 4.650924725392539e-05,
      "loss": 0.4563,
      "step": 550
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 17.13434600830078,
      "learning_rate": 4.586337299024986e-05,
      "loss": 0.4807,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7912087912087912,
      "eval_f1": 0.7557840616966581,
      "eval_loss": 0.44876715540885925,
      "eval_precision": 0.7882037533512064,
      "eval_recall": 0.725925925925926,
      "eval_runtime": 2.2428,
      "eval_samples_per_second": 405.735,
      "eval_steps_per_second": 25.414,
      "step": 645
    },
    {
      "epoch": 1.0077519379844961,
      "grad_norm": 4.605597972869873,
      "learning_rate": 4.5168013110861265e-05,
      "loss": 0.445,
      "step": 650
    },
    {
      "epoch": 1.0852713178294573,
      "grad_norm": 6.19408655166626,
      "learning_rate": 4.442481693256898e-05,
      "loss": 0.4629,
      "step": 700
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 9.457572937011719,
      "learning_rate": 4.363554723459841e-05,
      "loss": 0.4048,
      "step": 750
    },
    {
      "epoch": 1.2403100775193798,
      "grad_norm": 8.871179580688477,
      "learning_rate": 4.280207607747329e-05,
      "loss": 0.4667,
      "step": 800
    },
    {
      "epoch": 1.3178294573643412,
      "grad_norm": 6.419399738311768,
      "learning_rate": 4.1926380362695074e-05,
      "loss": 0.3788,
      "step": 850
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 7.805619716644287,
      "learning_rate": 4.1010537143750915e-05,
      "loss": 0.3936,
      "step": 900
    },
    {
      "epoch": 1.4728682170542635,
      "grad_norm": 3.647515296936035,
      "learning_rate": 4.005671869957228e-05,
      "loss": 0.5035,
      "step": 950
    },
    {
      "epoch": 1.550387596899225,
      "grad_norm": 9.941667556762695,
      "learning_rate": 3.9067187382129314e-05,
      "loss": 0.3852,
      "step": 1000
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 10.249479293823242,
      "learning_rate": 3.804429025038197e-05,
      "loss": 0.4011,
      "step": 1050
    },
    {
      "epoch": 1.7054263565891472,
      "grad_norm": 8.857407569885254,
      "learning_rate": 3.699045350331537e-05,
      "loss": 0.4879,
      "step": 1100
    },
    {
      "epoch": 1.7829457364341086,
      "grad_norm": 7.761202335357666,
      "learning_rate": 3.590817672526394e-05,
      "loss": 0.3545,
      "step": 1150
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 5.6601738929748535,
      "learning_rate": 3.480002695717351e-05,
      "loss": 0.4215,
      "step": 1200
    },
    {
      "epoch": 1.937984496124031,
      "grad_norm": 13.64196491241455,
      "learning_rate": 3.366863260786378e-05,
      "loss": 0.3719,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8142857142857143,
      "eval_f1": 0.8018757327080891,
      "eval_loss": 0.46300438046455383,
      "eval_precision": 0.7633928571428571,
      "eval_recall": 0.8444444444444444,
      "eval_runtime": 2.2338,
      "eval_samples_per_second": 407.385,
      "eval_steps_per_second": 25.518,
      "step": 1290
    },
    {
      "epoch": 2.0155038759689923,
      "grad_norm": 14.719664573669434,
      "learning_rate": 3.2516677219732995e-05,
      "loss": 0.3368,
      "step": 1300
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 12.312702178955078,
      "learning_rate": 3.134689310369188e-05,
      "loss": 0.3523,
      "step": 1350
    },
    {
      "epoch": 2.1705426356589146,
      "grad_norm": 19.100597381591797,
      "learning_rate": 3.0162054858423993e-05,
      "loss": 0.3636,
      "step": 1400
    },
    {
      "epoch": 2.248062015503876,
      "grad_norm": 20.28233528137207,
      "learning_rate": 2.8964972789344252e-05,
      "loss": 0.3565,
      "step": 1450
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 21.087032318115234,
      "learning_rate": 2.7758486242864902e-05,
      "loss": 0.3581,
      "step": 1500
    },
    {
      "epoch": 2.4031007751937983,
      "grad_norm": 3.9075064659118652,
      "learning_rate": 2.6545456871779582e-05,
      "loss": 0.3236,
      "step": 1550
    },
    {
      "epoch": 2.4806201550387597,
      "grad_norm": 4.241498947143555,
      "learning_rate": 2.5328761847739014e-05,
      "loss": 0.3088,
      "step": 1600
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 5.569585800170898,
      "learning_rate": 2.4111287036917767e-05,
      "loss": 0.3407,
      "step": 1650
    },
    {
      "epoch": 2.6356589147286824,
      "grad_norm": 6.481616973876953,
      "learning_rate": 2.2895920155058478e-05,
      "loss": 0.3299,
      "step": 1700
    },
    {
      "epoch": 2.7131782945736433,
      "grad_norm": 8.993391990661621,
      "learning_rate": 2.1685543918129185e-05,
      "loss": 0.3852,
      "step": 1750
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 38.02138900756836,
      "learning_rate": 2.0483029204839515e-05,
      "loss": 0.3619,
      "step": 1800
    },
    {
      "epoch": 2.8682170542635657,
      "grad_norm": 6.711629390716553,
      "learning_rate": 1.9291228247233605e-05,
      "loss": 0.2972,
      "step": 1850
    },
    {
      "epoch": 2.945736434108527,
      "grad_norm": 14.807472229003906,
      "learning_rate": 1.8112967865510765e-05,
      "loss": 0.3406,
      "step": 1900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8219780219780219,
      "eval_f1": 0.7995049504950495,
      "eval_loss": 0.5630117654800415,
      "eval_precision": 0.8014888337468983,
      "eval_recall": 0.7975308641975308,
      "eval_runtime": 2.2258,
      "eval_samples_per_second": 408.835,
      "eval_steps_per_second": 25.608,
      "step": 1935
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 4.351890563964844,
      "learning_rate": 1.695104276312028e-05,
      "loss": 0.3139,
      "step": 1950
    },
    {
      "epoch": 3.10077519379845,
      "grad_norm": 11.711259841918945,
      "learning_rate": 1.5808208898033625e-05,
      "loss": 0.2908,
      "step": 2000
    },
    {
      "epoch": 3.1782945736434107,
      "grad_norm": 19.923847198486328,
      "learning_rate": 1.468717694591662e-05,
      "loss": 0.2226,
      "step": 2050
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 1.5575268268585205,
      "learning_rate": 1.3590605870706238e-05,
      "loss": 0.2525,
      "step": 2100
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 13.258401870727539,
      "learning_rate": 1.2521096617841903e-05,
      "loss": 0.3512,
      "step": 2150
    },
    {
      "epoch": 3.4108527131782944,
      "grad_norm": 4.758035182952881,
      "learning_rate": 1.148118594511025e-05,
      "loss": 0.2791,
      "step": 2200
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 6.352604866027832,
      "learning_rate": 1.0473340405735974e-05,
      "loss": 0.2727,
      "step": 2250
    },
    {
      "epoch": 3.565891472868217,
      "grad_norm": 13.28359603881836,
      "learning_rate": 9.49995049799002e-06,
      "loss": 0.2819,
      "step": 2300
    },
    {
      "epoch": 3.6434108527131785,
      "grad_norm": 2.905078887939453,
      "learning_rate": 8.56332499519186e-06,
      "loss": 0.305,
      "step": 2350
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 1.6489931344985962,
      "learning_rate": 7.66568546955419e-06,
      "loss": 0.2893,
      "step": 2400
    },
    {
      "epoch": 3.798449612403101,
      "grad_norm": 2.671215057373047,
      "learning_rate": 6.809161022859129e-06,
      "loss": 0.314,
      "step": 2450
    },
    {
      "epoch": 3.875968992248062,
      "grad_norm": 0.5508418083190918,
      "learning_rate": 5.995783236464014e-06,
      "loss": 0.261,
      "step": 2500
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 10.589035034179688,
      "learning_rate": 5.22748135261486e-06,
      "loss": 0.2228,
      "step": 2550
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8175824175824176,
      "eval_f1": 0.7945544554455446,
      "eval_loss": 0.6329092383384705,
      "eval_precision": 0.7965260545905707,
      "eval_recall": 0.7925925925925926,
      "eval_runtime": 2.2367,
      "eval_samples_per_second": 406.853,
      "eval_steps_per_second": 25.484,
      "step": 2580
    },
    {
      "epoch": 4.0310077519379846,
      "grad_norm": 0.3230704665184021,
      "learning_rate": 4.506077698496897e-06,
      "loss": 0.254,
      "step": 2600
    },
    {
      "epoch": 4.108527131782946,
      "grad_norm": 10.697522163391113,
      "learning_rate": 3.833283363875823e-06,
      "loss": 0.2456,
      "step": 2650
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 4.814517974853516,
      "learning_rate": 3.210694142581938e-06,
      "loss": 0.1724,
      "step": 2700
    },
    {
      "epoch": 4.263565891472869,
      "grad_norm": 9.98061752319336,
      "learning_rate": 2.639786747463474e-06,
      "loss": 0.224,
      "step": 2750
    },
    {
      "epoch": 4.341085271317829,
      "grad_norm": 7.152087211608887,
      "learning_rate": 2.121915307786862e-06,
      "loss": 0.2072,
      "step": 2800
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 0.9153071641921997,
      "learning_rate": 1.6583081573917192e-06,
      "loss": 0.272,
      "step": 2850
    },
    {
      "epoch": 4.496124031007752,
      "grad_norm": 17.380847930908203,
      "learning_rate": 1.250064921218705e-06,
      "loss": 0.212,
      "step": 2900
    },
    {
      "epoch": 4.573643410852713,
      "grad_norm": 24.543169021606445,
      "learning_rate": 8.981539071206441e-07,
      "loss": 0.2959,
      "step": 2950
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 30.13980484008789,
      "learning_rate": 6.034098091432572e-07,
      "loss": 0.1935,
      "step": 3000
    },
    {
      "epoch": 4.728682170542635,
      "grad_norm": 19.55315399169922,
      "learning_rate": 3.665317277231406e-07,
      "loss": 0.3069,
      "step": 3050
    },
    {
      "epoch": 4.8062015503875966,
      "grad_norm": 32.984737396240234,
      "learning_rate": 1.8808151149874166e-07,
      "loss": 0.2742,
      "step": 3100
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 13.19800090789795,
      "learning_rate": 6.84824246674709e-08,
      "loss": 0.2362,
      "step": 3150
    },
    {
      "epoch": 4.961240310077519,
      "grad_norm": 12.835136413574219,
      "learning_rate": 8.018143049787207e-09,
      "loss": 0.2104,
      "step": 3200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8186813186813187,
      "eval_f1": 0.796044499381953,
      "eval_loss": 0.6693834662437439,
      "eval_precision": 0.7970297029702971,
      "eval_recall": 0.7950617283950617,
      "eval_runtime": 2.2437,
      "eval_samples_per_second": 405.582,
      "eval_steps_per_second": 25.405,
      "step": 3225
    }
  ],
  "logging_steps": 50,
  "max_steps": 3225,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.425225676161024e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
