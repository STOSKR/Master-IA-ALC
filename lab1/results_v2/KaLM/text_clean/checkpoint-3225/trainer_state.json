{
  "best_global_step": 3225,
  "best_metric": 0.795593635250918,
  "best_model_checkpoint": "../results_v2/KaLM/text_clean/checkpoint-3225",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3225,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07751937984496124,
      "grad_norm": 2.6211376190185547,
      "learning_rate": 4.997152524340171e-05,
      "loss": 0.6942,
      "step": 50
    },
    {
      "epoch": 0.15503875968992248,
      "grad_norm": 2.723548412322998,
      "learning_rate": 4.9883832649612775e-05,
      "loss": 0.6916,
      "step": 100
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 2.5033833980560303,
      "learning_rate": 4.973711835398576e-05,
      "loss": 0.6858,
      "step": 150
    },
    {
      "epoch": 0.31007751937984496,
      "grad_norm": 1.6849337816238403,
      "learning_rate": 4.953173034662064e-05,
      "loss": 0.6619,
      "step": 200
    },
    {
      "epoch": 0.3875968992248062,
      "grad_norm": 3.989504814147949,
      "learning_rate": 4.9268155785179295e-05,
      "loss": 0.6382,
      "step": 250
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 22.78419303894043,
      "learning_rate": 4.89470198394013e-05,
      "loss": 0.5877,
      "step": 300
    },
    {
      "epoch": 0.5426356589147286,
      "grad_norm": 9.88113784790039,
      "learning_rate": 4.856908420827041e-05,
      "loss": 0.5562,
      "step": 350
    },
    {
      "epoch": 0.6201550387596899,
      "grad_norm": 8.491555213928223,
      "learning_rate": 4.813524531334873e-05,
      "loss": 0.5553,
      "step": 400
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 24.223844528198242,
      "learning_rate": 4.7646532172563765e-05,
      "loss": 0.5185,
      "step": 450
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 19.350204467773438,
      "learning_rate": 4.710410395949164e-05,
      "loss": 0.5948,
      "step": 500
    },
    {
      "epoch": 0.8527131782945736,
      "grad_norm": 5.051694393157959,
      "learning_rate": 4.650924725392539e-05,
      "loss": 0.4555,
      "step": 550
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 5.129461765289307,
      "learning_rate": 4.586337299024986e-05,
      "loss": 0.5068,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.789010989010989,
      "eval_f1": 0.7480314960629921,
      "eval_loss": 0.4842877984046936,
      "eval_precision": 0.7983193277310925,
      "eval_recall": 0.7037037037037037,
      "eval_runtime": 2.2515,
      "eval_samples_per_second": 404.167,
      "eval_steps_per_second": 25.316,
      "step": 645
    },
    {
      "epoch": 1.0077519379844961,
      "grad_norm": 2.0503177642822266,
      "learning_rate": 4.5168013110861265e-05,
      "loss": 0.4507,
      "step": 650
    },
    {
      "epoch": 1.0852713178294573,
      "grad_norm": 8.688485145568848,
      "learning_rate": 4.442481693256898e-05,
      "loss": 0.471,
      "step": 700
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 12.531352043151855,
      "learning_rate": 4.363554723459841e-05,
      "loss": 0.432,
      "step": 750
    },
    {
      "epoch": 1.2403100775193798,
      "grad_norm": 10.295303344726562,
      "learning_rate": 4.280207607747329e-05,
      "loss": 0.4552,
      "step": 800
    },
    {
      "epoch": 1.3178294573643412,
      "grad_norm": 8.452448844909668,
      "learning_rate": 4.1926380362695074e-05,
      "loss": 0.3819,
      "step": 850
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 8.183576583862305,
      "learning_rate": 4.1010537143750915e-05,
      "loss": 0.402,
      "step": 900
    },
    {
      "epoch": 1.4728682170542635,
      "grad_norm": 4.96980094909668,
      "learning_rate": 4.005671869957228e-05,
      "loss": 0.5089,
      "step": 950
    },
    {
      "epoch": 1.550387596899225,
      "grad_norm": 13.52710247039795,
      "learning_rate": 3.9067187382129314e-05,
      "loss": 0.395,
      "step": 1000
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 9.502655029296875,
      "learning_rate": 3.804429025038197e-05,
      "loss": 0.3943,
      "step": 1050
    },
    {
      "epoch": 1.7054263565891472,
      "grad_norm": 8.768513679504395,
      "learning_rate": 3.699045350331537e-05,
      "loss": 0.4995,
      "step": 1100
    },
    {
      "epoch": 1.7829457364341086,
      "grad_norm": 10.339505195617676,
      "learning_rate": 3.590817672526394e-05,
      "loss": 0.3641,
      "step": 1150
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 6.223753452301025,
      "learning_rate": 3.480002695717351e-05,
      "loss": 0.4553,
      "step": 1200
    },
    {
      "epoch": 1.937984496124031,
      "grad_norm": 13.362347602844238,
      "learning_rate": 3.366863260786378e-05,
      "loss": 0.3666,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8098901098901099,
      "eval_f1": 0.792814371257485,
      "eval_loss": 0.4665168225765228,
      "eval_precision": 0.7697674418604651,
      "eval_recall": 0.817283950617284,
      "eval_runtime": 2.2538,
      "eval_samples_per_second": 403.76,
      "eval_steps_per_second": 25.29,
      "step": 1290
    },
    {
      "epoch": 2.0155038759689923,
      "grad_norm": 13.372552871704102,
      "learning_rate": 3.2516677219732995e-05,
      "loss": 0.3744,
      "step": 1300
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 9.800583839416504,
      "learning_rate": 3.134689310369188e-05,
      "loss": 0.3716,
      "step": 1350
    },
    {
      "epoch": 2.1705426356589146,
      "grad_norm": 18.650402069091797,
      "learning_rate": 3.0162054858423993e-05,
      "loss": 0.3526,
      "step": 1400
    },
    {
      "epoch": 2.248062015503876,
      "grad_norm": 16.75870132446289,
      "learning_rate": 2.8964972789344252e-05,
      "loss": 0.3472,
      "step": 1450
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 21.69788360595703,
      "learning_rate": 2.7758486242864902e-05,
      "loss": 0.3671,
      "step": 1500
    },
    {
      "epoch": 2.4031007751937983,
      "grad_norm": 8.588232040405273,
      "learning_rate": 2.6545456871779582e-05,
      "loss": 0.3486,
      "step": 1550
    },
    {
      "epoch": 2.4806201550387597,
      "grad_norm": 4.641170978546143,
      "learning_rate": 2.5328761847739014e-05,
      "loss": 0.3301,
      "step": 1600
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 8.316530227661133,
      "learning_rate": 2.4111287036917767e-05,
      "loss": 0.3559,
      "step": 1650
    },
    {
      "epoch": 2.6356589147286824,
      "grad_norm": 4.296865463256836,
      "learning_rate": 2.2895920155058478e-05,
      "loss": 0.3049,
      "step": 1700
    },
    {
      "epoch": 2.7131782945736433,
      "grad_norm": 11.48245620727539,
      "learning_rate": 2.1685543918129185e-05,
      "loss": 0.35,
      "step": 1750
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 60.52178955078125,
      "learning_rate": 2.0483029204839515e-05,
      "loss": 0.326,
      "step": 1800
    },
    {
      "epoch": 2.8682170542635657,
      "grad_norm": 16.42995262145996,
      "learning_rate": 1.9291228247233605e-05,
      "loss": 0.3457,
      "step": 1850
    },
    {
      "epoch": 2.945736434108527,
      "grad_norm": 18.387054443359375,
      "learning_rate": 1.8112967865510765e-05,
      "loss": 0.368,
      "step": 1900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8087912087912088,
      "eval_f1": 0.7814070351758794,
      "eval_loss": 0.5793760418891907,
      "eval_precision": 0.7953964194373402,
      "eval_recall": 0.7679012345679013,
      "eval_runtime": 2.234,
      "eval_samples_per_second": 407.35,
      "eval_steps_per_second": 25.515,
      "step": 1935
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 1.6200480461120605,
      "learning_rate": 1.695104276312028e-05,
      "loss": 0.3106,
      "step": 1950
    },
    {
      "epoch": 3.10077519379845,
      "grad_norm": 10.22025203704834,
      "learning_rate": 1.5808208898033625e-05,
      "loss": 0.3073,
      "step": 2000
    },
    {
      "epoch": 3.1782945736434107,
      "grad_norm": 16.760107040405273,
      "learning_rate": 1.468717694591662e-05,
      "loss": 0.2514,
      "step": 2050
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 2.2386672496795654,
      "learning_rate": 1.3590605870706238e-05,
      "loss": 0.2932,
      "step": 2100
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 6.37955379486084,
      "learning_rate": 1.2521096617841903e-05,
      "loss": 0.3422,
      "step": 2150
    },
    {
      "epoch": 3.4108527131782944,
      "grad_norm": 5.142744064331055,
      "learning_rate": 1.148118594511025e-05,
      "loss": 0.271,
      "step": 2200
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 11.846749305725098,
      "learning_rate": 1.0473340405735974e-05,
      "loss": 0.2414,
      "step": 2250
    },
    {
      "epoch": 3.565891472868217,
      "grad_norm": 7.559638977050781,
      "learning_rate": 9.49995049799002e-06,
      "loss": 0.2609,
      "step": 2300
    },
    {
      "epoch": 3.6434108527131785,
      "grad_norm": 13.463818550109863,
      "learning_rate": 8.56332499519186e-06,
      "loss": 0.3316,
      "step": 2350
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 0.6143261194229126,
      "learning_rate": 7.66568546955419e-06,
      "loss": 0.303,
      "step": 2400
    },
    {
      "epoch": 3.798449612403101,
      "grad_norm": 8.011736869812012,
      "learning_rate": 6.809161022859129e-06,
      "loss": 0.3215,
      "step": 2450
    },
    {
      "epoch": 3.875968992248062,
      "grad_norm": 0.621570885181427,
      "learning_rate": 5.995783236464014e-06,
      "loss": 0.2525,
      "step": 2500
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 8.477734565734863,
      "learning_rate": 5.22748135261486e-06,
      "loss": 0.2129,
      "step": 2550
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8153846153846154,
      "eval_f1": 0.7951219512195122,
      "eval_loss": 0.6002215147018433,
      "eval_precision": 0.7855421686746988,
      "eval_recall": 0.8049382716049382,
      "eval_runtime": 2.2542,
      "eval_samples_per_second": 403.691,
      "eval_steps_per_second": 25.286,
      "step": 2580
    },
    {
      "epoch": 4.0310077519379846,
      "grad_norm": 0.3530745506286621,
      "learning_rate": 4.506077698496897e-06,
      "loss": 0.2134,
      "step": 2600
    },
    {
      "epoch": 4.108527131782946,
      "grad_norm": 11.452080726623535,
      "learning_rate": 3.833283363875823e-06,
      "loss": 0.2349,
      "step": 2650
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 4.938698768615723,
      "learning_rate": 3.210694142581938e-06,
      "loss": 0.1897,
      "step": 2700
    },
    {
      "epoch": 4.263565891472869,
      "grad_norm": 7.155317783355713,
      "learning_rate": 2.639786747463474e-06,
      "loss": 0.2038,
      "step": 2750
    },
    {
      "epoch": 4.341085271317829,
      "grad_norm": 18.877212524414062,
      "learning_rate": 2.121915307786862e-06,
      "loss": 0.2236,
      "step": 2800
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 1.7393312454223633,
      "learning_rate": 1.6583081573917192e-06,
      "loss": 0.2664,
      "step": 2850
    },
    {
      "epoch": 4.496124031007752,
      "grad_norm": 14.170741081237793,
      "learning_rate": 1.250064921218705e-06,
      "loss": 0.2509,
      "step": 2900
    },
    {
      "epoch": 4.573643410852713,
      "grad_norm": 12.015596389770508,
      "learning_rate": 8.981539071206441e-07,
      "loss": 0.2865,
      "step": 2950
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 18.818531036376953,
      "learning_rate": 6.034098091432572e-07,
      "loss": 0.1817,
      "step": 3000
    },
    {
      "epoch": 4.728682170542635,
      "grad_norm": 27.38513946533203,
      "learning_rate": 3.665317277231406e-07,
      "loss": 0.3152,
      "step": 3050
    },
    {
      "epoch": 4.8062015503875966,
      "grad_norm": 30.14118003845215,
      "learning_rate": 1.8808151149874166e-07,
      "loss": 0.3379,
      "step": 3100
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 10.44838809967041,
      "learning_rate": 6.84824246674709e-08,
      "loss": 0.2618,
      "step": 3150
    },
    {
      "epoch": 4.961240310077519,
      "grad_norm": 3.057673692703247,
      "learning_rate": 8.018143049787207e-09,
      "loss": 0.2335,
      "step": 3200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8164835164835165,
      "eval_f1": 0.795593635250918,
      "eval_loss": 0.6411540508270264,
      "eval_precision": 0.7888349514563107,
      "eval_recall": 0.8024691358024691,
      "eval_runtime": 2.2567,
      "eval_samples_per_second": 403.252,
      "eval_steps_per_second": 25.259,
      "step": 3225
    }
  ],
  "logging_steps": 50,
  "max_steps": 3225,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.425225676161024e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
